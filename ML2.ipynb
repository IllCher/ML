{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq0wc3K0kBqA"
      },
      "source": [
        "# Лабораторная работа 2 по МО"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s8Spsp5d-b-"
      },
      "source": [
        "Выбранный набор данных позволяет нам предсказать вероятность появления диабета у индийских пим в течение 5 лет, исходя из различных медицинских параметров."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKDoBesBAZzT"
      },
      "source": [
        "Подключим необходимые библиотеки, подгрузим данные и удалим ненужные параметры"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMnfK4-xd-b_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics  \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from collections import Counter\n",
        "from numpy import log, dot, e\n",
        "from numpy.random import rand\n",
        "\n",
        "\n",
        "dataframe = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv', header=None)\n",
        "dataframe.columns = ['Times pregnant', 'Glucose concentration', 'Blood pressure', 'Skinfold thickness', 'Serum insulin',\n",
        "                     'BMI', 'Pedigree', 'Age', 'Class']\n",
        "del dataframe['Skinfold thickness']\n",
        "del dataframe['Serum insulin']\n",
        "dataframe['Glucose concentration'] = dataframe['Glucose concentration'].replace(0, dataframe['Glucose concentration'].std())\n",
        "dataframe['Blood pressure'] = dataframe['Blood pressure'].replace(0, dataframe['Blood pressure'].std())\n",
        "dataframe['BMI'] = dataframe['BMI'].replace(0, dataframe['BMI'].std())\n",
        "\n"
      ],
      "execution_count": 881,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy_2cdtpd-cA"
      },
      "source": [
        "Вывод для атрибутов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIZ7AToOd-cA",
        "outputId": "259c26dc-7070-4bf1-956c-5d94159e72a1"
      },
      "source": [
        "print(dataframe.head())\n",
        "print(\"Размеры:\",dataframe.shape)\n",
        "print(\"Устройство:\\n\",dataframe.dtypes)"
      ],
      "execution_count": 882,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Times pregnant  Glucose concentration  Blood pressure  ...  Pedigree  Age  Class\n",
            "0               6                  148.0            72.0  ...     0.627   50      1\n",
            "1               1                   85.0            66.0  ...     0.351   31      0\n",
            "2               8                  183.0            64.0  ...     0.672   32      1\n",
            "3               1                   89.0            66.0  ...     0.167   21      0\n",
            "4               0                  137.0            40.0  ...     2.288   33      1\n",
            "\n",
            "[5 rows x 7 columns]\n",
            "Размеры: (768, 7)\n",
            "Устройство:\n",
            " Times pregnant             int64\n",
            "Glucose concentration    float64\n",
            "Blood pressure           float64\n",
            "BMI                      float64\n",
            "Pedigree                 float64\n",
            "Age                        int64\n",
            "Class                      int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_AYsxBNd-cC"
      },
      "source": [
        "Подгружаем данные и переводим их в удобный формат:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V-8EUm6aGzf"
      },
      "source": [
        "X = dataframe.iloc[:, :-1].values\n",
        "Y = dataframe.iloc[:, 6].values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,  random_state=0)\n",
        "trans = StandardScaler()\n",
        "X_train = trans.fit_transform(X_train)\n",
        "X_test = trans.fit_transform(X_test)"
      ],
      "execution_count": 883,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "a1kb_nnkd-cD"
      },
      "source": [
        "####Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxMBxq3Bd-cD"
      },
      "source": [
        "class MyLogisticRegression:\n",
        "    def sigmoid(self, z): return 1 / (1 + e**(-z))\n",
        "    \n",
        "    def cost_function(self, X, y, weights):                 \n",
        "        z = dot(X, weights)\n",
        "        predict_1 = y * log(self.sigmoid(z))\n",
        "        predict_0 = (1 - y) * log(1 - self.sigmoid(z))\n",
        "        return -sum(predict_1 + predict_0) / len(X)\n",
        "    \n",
        "    def fit(self, X, y, epochs=25, lr=0.05):        \n",
        "        loss = []\n",
        "        weights = rand(X.shape[1])\n",
        "        N = len(X)\n",
        "                 \n",
        "        for _ in range(epochs):        \n",
        "            y_hat = self.sigmoid(dot(X, weights))\n",
        "            weights -= lr * dot(X.T,  y_hat - y) / N            \n",
        "            loss.append(self.cost_function(X, y, weights)) \n",
        "            \n",
        "        self.weights = weights\n",
        "        self.loss = loss\n",
        "    \n",
        "    def predict(self, X):        \n",
        "        z = dot(X, self.weights)\n",
        "        return [1 if i > 0.5 else 0 for i in self.sigmoid(z)]"
      ],
      "execution_count": 884,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCqg-UkXosq5"
      },
      "source": [
        "Моя реализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3UGxlOhoy6L",
        "outputId": "9db461ff-c9e3-49d2-88bd-16ef0803d737"
      },
      "source": [
        "parameters = [(0.1, 50), (0.1, 100), (0.1, 1000), (0.1, 10000),\n",
        "              (0.01, 50), (0.01, 100), (0.01, 1000), (0.01, 10000),\n",
        "              (0.001, 50), (0.001, 100), (0.001, 1000), (0.001, 10000),\n",
        "              (0.0001, 50), (0.0001, 100), (0.0001, 1000), (0.0001, 10000),\n",
        "              (0.00001, 50), (0.00001, 100), (0.00001, 1000), (0.00001, 10000)\n",
        "]\n",
        "train_max = -1\n",
        "test_max = -1\n",
        "learning_rate_max = 0\n",
        "epochs_max = 0\n",
        "for i in parameters:\n",
        "    learning_rate, epochs = i\n",
        "    my_regr = MyLogisticRegression()\n",
        "    my_regr.fit(X_train, Y_train, epochs, learning_rate)\n",
        "    Y_pred_test = my_regr.predict(X_test)\n",
        "    Y_pred_train = my_regr.predict(X_train)\n",
        "    accuracy_train = accuracy_score(Y_train, Y_pred_train)\n",
        "    accuracy_test = accuracy_score(Y_test, Y_pred_test)\n",
        "    if (train_max < accuracy_train and test_max < accuracy_test):\n",
        "      train_max = accuracy_train\n",
        "      test_max = accuracy_test\n",
        "      learning_rate_max = learning_rate\n",
        "      epochs_max = epochs\n",
        "print(\"Learning rate:\", learning_rate, \"epochs:\", epochs, \"\\n\", \"Max train accuracy:\", train_max, \"Max test accuracy:\", test_max)\n"
      ],
      "execution_count": 885,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate: 1e-05 epochs: 10000 \n",
            " Max train accuracy: 0.745928338762215 Max test accuracy: 0.7467532467532467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7lCggrTpYwz"
      },
      "source": [
        "Лучше всего себя показала модель с learning_rate равным 0.00001 и количеством эпох равным 10000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqx2kIKGfc62"
      },
      "source": [
        "my_regr = MyLogisticRegression()\n",
        "my_regr.fit(X_train, Y_train, epochs = 10000, lr = 0.00001)\n",
        "Y_pred = my_regr.predict(X_test)"
      ],
      "execution_count": 886,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O70LsbfRe71D"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WLHjtB-fAB8",
        "outputId": "ac436714-d9f6-4241-d531-965313dc2ca1"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": 887,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[75 32]\n",
            " [12 35]]\n",
            "accuracy: 0.7142857142857143\n",
            "precision: 0.5223880597014925\n",
            "recall: 0.7446808510638298\n",
            "f1_score 0.6140350877192982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eAb7NjKov0s"
      },
      "source": [
        "Реализация sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceHthIFqpuSO"
      },
      "source": [
        "sk_regr = LogisticRegression().fit(X_train, Y_train)\n",
        "Y_pred = sk_regr.predict(X_test)"
      ],
      "execution_count": 888,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x9DOR7QfD5G"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPOb5nAdfGRn",
        "outputId": "d16b2d9e-de57-41f9-edf0-d1a2f8758867"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": 889,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[94 13]\n",
            " [18 29]]\n",
            "accuracy: 0.7987012987012987\n",
            "precision: 0.6904761904761905\n",
            "recall: 0.6170212765957447\n",
            "f1_score 0.651685393258427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_7iG5CfEIl-"
      },
      "source": [
        "Получилась так, что в модели sklearn был оптимизирован параметр f1_score, что означает что модель попыталась достичь максимальной полноты и точности, а моя реализация наоборот получила максимальную полноту но меньшую точность."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "mcMUHEhrd-cE"
      },
      "source": [
        "####Дерево решений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrnQs-Oid-cF"
      },
      "source": [
        "\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, data_left=None, data_right=None, gain=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.data_left = data_left\n",
        "        self.data_right = data_right\n",
        "        self.gain = gain\n",
        "        self.value = value\n",
        "\n",
        "class MyDecisionTree:\n",
        "    def __init__(self, min_samples_split=2, max_depth=5):\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.root = None\n",
        "        \n",
        "    @staticmethod\n",
        "    def _entropy(s):\n",
        "        counts = np.bincount(np.array(s, dtype=np.int64))\n",
        "        percentages = counts / len(s)\n",
        "        entropy = 0\n",
        "        for pct in percentages:\n",
        "            if pct > 0:\n",
        "                entropy += pct * np.log2(pct)\n",
        "        return -entropy\n",
        "    \n",
        "    def _information_gain(self, parent, left_child, right_child):\n",
        "        num_left = len(left_child) / len(parent)\n",
        "        num_right = len(right_child) / len(parent)\n",
        "        return self._entropy(parent) - (num_left * self._entropy(left_child) + num_right * self._entropy(right_child))\n",
        "  \n",
        "    def _best_split(self, X, y):\n",
        "        best_split = {}\n",
        "        best_info_gain = -1\n",
        "        n_rows, n_cols = X.shape\n",
        " \n",
        "        for f_idx in range(n_cols):\n",
        "            X_curr = X[:, f_idx]\n",
        "\n",
        "            for threshold in np.unique(X_curr):\n",
        "\n",
        "                df = np.concatenate((X, y.reshape(1, -1).T), axis=1)\n",
        "                df_left = np.array([row for row in df if row[f_idx] <= threshold])\n",
        "                df_right = np.array([row for row in df if row[f_idx] > threshold])\n",
        "\n",
        "                if len(df_left) > 0 and len(df_right) > 0:\n",
        "                    y = df[:, -1]\n",
        "                    y_left = df_left[:, -1]\n",
        "                    y_right = df_right[:, -1]\n",
        "                    gain = self._information_gain(y, y_left, y_right)\n",
        "                    if gain > best_info_gain:\n",
        "                        best_split = {\n",
        "                            'feature_index': f_idx,\n",
        "                            'threshold': threshold,\n",
        "                            'df_left': df_left,\n",
        "                            'df_right': df_right,\n",
        "                            'gain': gain\n",
        "                        }\n",
        "                        best_info_gain = gain\n",
        "        return best_split\n",
        "    \n",
        "    def _build(self, X, y, depth=0):\n",
        "        n_rows, n_cols = X.shape\n",
        "        \n",
        "        if n_rows >= self.min_samples_split and depth <= self.max_depth:\n",
        "            best = self._best_split(X, y)\n",
        "            if best['gain'] > 0:\n",
        "                left = self._build(\n",
        "                    X=best['df_left'][:, :-1], \n",
        "                    y=best['df_left'][:, -1], \n",
        "                    depth=depth + 1\n",
        "                )\n",
        "                right = self._build(\n",
        "                    X=best['df_right'][:, :-1], \n",
        "                    y=best['df_right'][:, -1], \n",
        "                    depth=depth + 1\n",
        "                )\n",
        "                return Node(\n",
        "                    feature=best['feature_index'], \n",
        "                    threshold=best['threshold'], \n",
        "                    data_left=left, \n",
        "                    data_right=right, \n",
        "                    gain=best['gain']\n",
        "                )\n",
        "        return Node(\n",
        "            value=Counter(y).most_common(1)[0][0]\n",
        "        )\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.root = self._build(X, y)\n",
        "        \n",
        "    def _predict(self, x, tree):\n",
        "        if tree.value != None:\n",
        "            return tree.value\n",
        "        feature_value = x[tree.feature]\n",
        "\n",
        "        if feature_value <= tree.threshold:\n",
        "            return self._predict(x=x, tree=tree.data_left)\n",
        "        \n",
        "        if feature_value > tree.threshold:\n",
        "            return self._predict(x=x, tree=tree.data_right)\n",
        "        \n",
        "    def predict(self, X):\n",
        "        return [self._predict(x, self.root) for x in X]"
      ],
      "execution_count": 890,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "BQ-LGt5pd-cH"
      },
      "source": [
        "Моя реализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdQOfOohexK_",
        "outputId": "dcb1d1ce-4798-4d16-ee70-dc3d8127f63a"
      },
      "source": [
        "parameters = [(2, 1), (2, 2), (2, 3), (2, 10), (3, 15), \n",
        "              (3, 1), (3, 2), (3, 3), (3, 10), (3, 15), \n",
        "              (4, 1), (4, 2), (4, 3), (4, 10), (4, 15),\n",
        "              (5, 1), (5, 2), (5, 3), (5, 10), (5, 15),\n",
        "              (10, 1), (10, 2), (10, 3), (10, 10), (10, 15)\n",
        "              ]\n",
        "train_max = -1\n",
        "test_max = -1\n",
        "sample_split_max = 0\n",
        "depth_max = 0\n",
        "for i in parameters:\n",
        "    sample_split, depth = i\n",
        "    my_tree = MyDecisionTree(min_samples_split = sample_split, max_depth = depth)\n",
        "    my_tree.fit(X_train, Y_train)\n",
        "    Y_pred_test = my_tree.predict(X_test)\n",
        "    Y_pred_train = my_tree.predict(X_train)\n",
        "    accuracy_train = accuracy_score(Y_train, Y_pred_train)\n",
        "    accuracy_test = accuracy_score(Y_test, Y_pred_test)\n",
        "    if (train_max < accuracy_train and test_max < accuracy_test):\n",
        "      train_max = accuracy_train\n",
        "      test_max = accuracy_test\n",
        "      sample_split_max = sample_split\n",
        "      depth_max = depth \n",
        "print(\"Minimum sample splits:\", sample_split_max, \"Max depth:\", depth_max, \"\\n\", \"Max train accuracy:\", train_max, \"Max test accuracy:\", test_max)"
      ],
      "execution_count": 891,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum sample splits: 2 Max depth: 1 \n",
            " Max train accuracy: 0.7638436482084691 Max test accuracy: 0.7597402597402597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7lKTfWQ93Hk"
      },
      "source": [
        "Лучше всего себя показала модель с количеством образцов равным двум и максимальной глубиной равной 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4t0b7NOar1-"
      },
      "source": [
        "my_tree = MyDecisionTree(min_samples_split = 2, max_depth = 1)\n",
        "my_tree.fit(X_train, Y_train)\n",
        "Y_pred = my_tree.predict(X_test)"
      ],
      "execution_count": 892,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiL2YmXqadff"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUkHxeGfd-cI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008d134c-dc83-4702-d72c-335338835c3e"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": 893,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[92 15]\n",
            " [22 25]]\n",
            "accuracy: 0.7597402597402597\n",
            "precision: 0.625\n",
            "recall: 0.5319148936170213\n",
            "f1_score 0.5747126436781609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "51nlLkFMd-cI"
      },
      "source": [
        "Реализация sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65EmQmGjd-cJ"
      },
      "source": [
        "sk_tree = DecisionTree()\n",
        "sk_tree.fit(X_train, Y_train)\n",
        "Y_pred = sk_tree.predict(X_test)\n"
      ],
      "execution_count": 894,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQEX-6J63H3n"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iDMHfpz3Q9v",
        "outputId": "b11b6023-8e15-4f03-8c16-412a6be46579"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": 895,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[94 13]\n",
            " [24 23]]\n",
            "accuracy: 0.7597402597402597\n",
            "precision: 0.6388888888888888\n",
            "recall: 0.48936170212765956\n",
            "f1_score 0.5542168674698795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94gaAue7-EHU"
      },
      "source": [
        "Из-за особенностей нашего набора данных большинство метрик получились довольно низкими не считая простой вероятности, т.к. как можно заметить у нас очень мало положительных случаев true positive (23), что ведет к низкому recall и precision, то есть полноте и точности, и как следствие f1_score тоже низок."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BYMa4tnd-cJ"
      },
      "source": [
        "####Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgHtKAeKd-cK"
      },
      "source": [
        "class MyRandomForest:\n",
        "    def __init__(self, num_trees=25, min_samples_split=2, max_depth=5):\n",
        "        self.num_trees = num_trees\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.decision_trees = []\n",
        "        \n",
        "    @staticmethod\n",
        "    def _sample(X, y):\n",
        "        n_rows, n_cols = X.shape\n",
        "        samples = np.random.choice(a=n_rows, size=n_rows, replace=True)\n",
        "        return X[samples], y[samples]\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        if len(self.decision_trees) > 0:\n",
        "            self.decision_trees = []\n",
        "        num_built = 0\n",
        "        while num_built < self.num_trees:\n",
        "            try:\n",
        "                clf = MyDecisionTree(\n",
        "                    min_samples_split=self.min_samples_split,\n",
        "                    max_depth=self.max_depth\n",
        "                )\n",
        "                _X, _y = self._sample(X, y)\n",
        "                clf.fit(_X, _y)\n",
        "                self.decision_trees.append(clf)\n",
        "                num_built += 1\n",
        "            except Exception as e:\n",
        "                continue\n",
        "    \n",
        "    def predict(self, X):\n",
        "        y = []\n",
        "        for tree in self.decision_trees:\n",
        "            y.append(tree.predict(X))\n",
        "        y = np.swapaxes(a=y, axis1=0, axis2=1)\n",
        "        predictions = []\n",
        "        for preds in y:\n",
        "            counter = Counter(preds)\n",
        "            predictions.append(counter.most_common(1)[0][0])\n",
        "        return predictions"
      ],
      "execution_count": 896,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "2H47Y3-mCbQy"
      },
      "source": [
        "Моя реализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxYl393ffAGv",
        "outputId": "92d98786-15e8-4077-ca4b-e5cc8dbf5abe"
      },
      "source": [
        "parameters = [(2, 2, 1), (5, 2, 1), (10, 2, 1), (20, 2, 1), (25, 2, 1)]\n",
        "train_max = -1\n",
        "test_max = -1\n",
        "sample_split_max = 0\n",
        "depth_max = 0\n",
        "tree_count_max = 0\n",
        "for i in parameters:\n",
        "    tree_count, sample_split, depth = i\n",
        "    my_forest = MyRandomForest(num_trees = tree_count, min_samples_split = sample_split, max_depth = depth)\n",
        "    my_forest.fit(X_train, Y_train)\n",
        "    Y_pred_test = my_forest.predict(X_test)\n",
        "    Y_pred_train = my_forest.predict(X_train)\n",
        "    accuracy_train = accuracy_score(Y_train, Y_pred_train)\n",
        "    accuracy_test = accuracy_score(Y_test, Y_pred_test)\n",
        "    if (train_max < accuracy_train and test_max < accuracy_test):\n",
        "      train_max = accuracy_train\n",
        "      test_max = accuracy_test\n",
        "      sample_split_max = sample_split\n",
        "      depth_max = depth\n",
        "      tree_count_max = tree_count\n",
        "print(\"Tree count:\", tree_count_max, \"Minimum sample splits:\", sample_split_max, \"Max depth:\", depth_max, \"\\n\", \"Max train accuracy:\", train_max, \"Max test accuracy:\", test_max)"
      ],
      "execution_count": 897,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tree count: 10 Minimum sample splits: 2 Max depth: 1 \n",
            " Max train accuracy: 0.7719869706840391 Max test accuracy: 0.7727272727272727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArQjJ_GmBtGd"
      },
      "source": [
        "Лучше всего себя показала модель с количеством деревьев равным 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_otYQcNJC917"
      },
      "source": [
        "my_forest = MyRandomForest(num_trees = 10, min_samples_split = 2, max_depth = 1)\n",
        "my_forest.fit(X_train, Y_train)\n",
        "Y_pred = my_tree.predict(X_test)\n"
      ],
      "execution_count": 898,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQdyW2LkCenG"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kAXx0gNC-V3",
        "outputId": "b39886b8-11f3-466d-997a-a88fb4e13cac"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": 899,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[92 15]\n",
            " [22 25]]\n",
            "accuracy: 0.7597402597402597\n",
            "precision: 0.625\n",
            "recall: 0.5319148936170213\n",
            "f1_score 0.5747126436781609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "NCOW1slvC6pu"
      },
      "source": [
        "Реализация sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzcr-TGmC-xL"
      },
      "source": [
        "sk_forest = RandomForestClassifier()\n",
        "sk_forest.fit(X_train, Y_train)\n",
        "Y_pred = sk_forest.predict(X_test)"
      ],
      "execution_count": 900,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRNKh7gmC7z2"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWgn_oGpC_Ul",
        "outputId": "6fa2ab7e-86b2-4df5-b59a-6bdd34bdc717"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": 901,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[92 15]\n",
            " [15 32]]\n",
            "accuracy: 0.8051948051948052\n",
            "precision: 0.6808510638297872\n",
            "recall: 0.6808510638297872\n",
            "f1_score 0.6808510638297872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_PYoYwPJKK_"
      },
      "source": [
        "В данном случае реализация sklearn значительно превзошла мою реализацию вероятнее всего в силу подборов оптимальных параметров, хотя вероятностная точность моей реализации всё ещё на достойном уровне."
      ]
    }
  ]
}