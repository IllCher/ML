{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq0wc3K0kBqA"
      },
      "source": [
        "# Лабораторная работа 2 по МО"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s8Spsp5d-b-"
      },
      "source": [
        "Выбранный набор данных позволяет нам предсказать вероятность появления диабета у индийских пим в течение 5 лет, исходя из различных медицинских параметров."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKDoBesBAZzT"
      },
      "source": [
        "Подключим необходимые библиотеки, подгрузим данные и удалим ненужные параметры"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMnfK4-xd-b_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics  \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from collections import Counter\n",
        "from numpy import log, dot, e\n",
        "from numpy.random import rand\n",
        "\n",
        "\n",
        "dataframe = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv', header=None)\n",
        "dataframe.columns = ['Times pregnant', 'Glucose concentration', 'Blood pressure', 'Skinfold thickness', 'Serum insulin',\n",
        "                     'BMI', 'Pedigree', 'Age', 'Class']\n",
        "del dataframe['Skinfold thickness']\n",
        "del dataframe['Serum insulin']\n",
        "dataframe['Glucose concentration'] = dataframe['Glucose concentration'].replace(0, dataframe['Glucose concentration'].std())\n",
        "dataframe['Blood pressure'] = dataframe['Blood pressure'].replace(0, dataframe['Blood pressure'].std())\n",
        "dataframe['BMI'] = dataframe['BMI'].replace(0, dataframe['BMI'].std())\n",
        "\n"
      ],
      "execution_count": 772,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy_2cdtpd-cA"
      },
      "source": [
        "Вывод для атрибутов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIZ7AToOd-cA",
        "outputId": "56479e4d-d639-4467-d920-a02ce9fd1042"
      },
      "source": [
        "print(dataframe.head())\n",
        "print(\"Размеры:\",dataframe.shape)\n",
        "print(\"Устройство:\\n\",dataframe.dtypes)"
      ],
      "execution_count": 773,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Times pregnant  Glucose concentration  Blood pressure  ...  Pedigree  Age  Class\n",
            "0               6                  148.0            72.0  ...     0.627   50      1\n",
            "1               1                   85.0            66.0  ...     0.351   31      0\n",
            "2               8                  183.0            64.0  ...     0.672   32      1\n",
            "3               1                   89.0            66.0  ...     0.167   21      0\n",
            "4               0                  137.0            40.0  ...     2.288   33      1\n",
            "\n",
            "[5 rows x 7 columns]\n",
            "Размеры: (768, 7)\n",
            "Устройство:\n",
            " Times pregnant             int64\n",
            "Glucose concentration    float64\n",
            "Blood pressure           float64\n",
            "BMI                      float64\n",
            "Pedigree                 float64\n",
            "Age                        int64\n",
            "Class                      int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_AYsxBNd-cC"
      },
      "source": [
        "Подгружаем данные и переводим их в удобный формат:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V-8EUm6aGzf"
      },
      "source": [
        "X = dataframe.iloc[:, :-1].values\n",
        "Y = dataframe.iloc[:, 6].values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,  random_state=0)\n",
        "trans = StandardScaler()\n",
        "X_train = trans.fit_transform(X_train)\n",
        "X_test = trans.fit_transform(X_test)"
      ],
      "execution_count": 774,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "a1kb_nnkd-cD"
      },
      "source": [
        "    ####Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxMBxq3Bd-cD"
      },
      "source": [
        "class MyLogisticRegression:\n",
        "    def sigmoid(self, z): return 1 / (1 + e**(-z))\n",
        "    \n",
        "    def cost_function(self, X, y, weights):                 \n",
        "        z = dot(X, weights)\n",
        "        predict_1 = y * log(self.sigmoid(z))\n",
        "        predict_0 = (1 - y) * log(1 - self.sigmoid(z))\n",
        "        return -sum(predict_1 + predict_0) / len(X)\n",
        "    \n",
        "    def fit(self, X, y, epochs=25, lr=0.05):        \n",
        "        loss = []\n",
        "        weights = rand(X.shape[1])\n",
        "        N = len(X)\n",
        "                 \n",
        "        for _ in range(epochs):        \n",
        "            y_hat = self.sigmoid(dot(X, weights))\n",
        "            weights -= lr * dot(X.T,  y_hat - y) / N            \n",
        "            loss.append(self.cost_function(X, y, weights)) \n",
        "            \n",
        "        self.weights = weights\n",
        "        self.loss = loss\n",
        "    \n",
        "    def predict(self, X):        \n",
        "        z = dot(X, self.weights)\n",
        "        return [1 if i > 0.5 else 0 for i in self.sigmoid(z)]"
      ],
      "execution_count": 775,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCqg-UkXosq5"
      },
      "source": [
        "Моя реализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3UGxlOhoy6L",
        "outputId": "5ab358ba-07c7-472b-9304-de65866d5843"
      },
      "source": [
        "parameters = [(0.1, 50), (0.1, 100), (0.1, 1000), (0.1, 10000),\n",
        "              (0.01, 50), (0.01, 100), (0.01, 1000), (0.01, 10000),\n",
        "              (0.001, 50), (0.001, 100), (0.001, 1000), (0.001, 10000),\n",
        "              (0.0001, 50), (0.0001, 100), (0.0001, 1000), (0.0001, 10000),\n",
        "              (0.00001, 50), (0.00001, 100), (0.00001, 1000), (0.00001, 10000)\n",
        "]\n",
        "train_max = -1\n",
        "test_max = -1\n",
        "learning_rate_max = 0\n",
        "epochs_max = 0\n",
        "for i in parameters:\n",
        "    learning_rate, epochs = i\n",
        "    my_regr = MyLogisticRegression()\n",
        "    my_regr.fit(X_train, Y_train, epochs, learning_rate)\n",
        "    Y_pred_test = my_regr.predict(X_test)\n",
        "    Y_pred_train = my_regr.predict(X_train)\n",
        "    accuracy_train = accuracy_score(Y_train, Y_pred_train)\n",
        "    accuracy_test = accuracy_score(Y_test, Y_pred_test)\n",
        "    if (train_max < accuracy_train and test_max < accuracy_test):\n",
        "      train_max = accuracy_train\n",
        "      test_max = accuracy_test\n",
        "      learning_rate_max = learning_rate\n",
        "      epochs_max = epochs\n",
        "print(\"Learning rate:\", learning_rate, \"epochs:\", epochs, \"\\n\", \"Max train accuracy:\", train_max, \"Max test accuracy:\", test_max)\n"
      ],
      "execution_count": 776,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate: 1e-05 epochs: 10000 \n",
            " Max train accuracy: 0.739413680781759 Max test accuracy: 0.7467532467532467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7lCggrTpYwz"
      },
      "source": [
        "Лучше всего себя показала модель с learning_rate равным 0.00001 и количеством эпох равным 10000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqx2kIKGfc62"
      },
      "source": [
        "my_regr = MyLogisticRegression()\n",
        "my_regr.fit(X_train, Y_train, epochs = 10000, lr = 0.00001)\n",
        "Y_pred = my_regr.predict(X_test)"
      ],
      "execution_count": 777,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O70LsbfRe71D"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WLHjtB-fAB8",
        "outputId": "5c05fae7-ffc2-425c-9f2e-68e3156cff3d"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": 778,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[75 32]\n",
            " [11 36]]\n",
            "accuracy: 0.7207792207792207\n",
            "precision: 0.5294117647058824\n",
            "recall: 0.7659574468085106\n",
            "f1_score 0.6260869565217391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eAb7NjKov0s"
      },
      "source": [
        "Реализация sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceHthIFqpuSO"
      },
      "source": [
        "sk_regr = LogisticRegression().fit(X_train, Y_train)\n",
        "Y_pred = sk_regr.predict(X_test)"
      ],
      "execution_count": 797,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x9DOR7QfD5G"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPOb5nAdfGRn",
        "outputId": "42d5b2ce-a269-44d3-f5f1-97341237b6e6"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": 798,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[94 13]\n",
            " [18 29]]\n",
            "accuracy: 0.7987012987012987\n",
            "precision: 0.6904761904761905\n",
            "recall: 0.6170212765957447\n",
            "f1_score 0.651685393258427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_7iG5CfEIl-"
      },
      "source": [
        "Получилась так, что в модели sklearn был оптимизирован параметр f1_score, что означает что модель попыталась достичь максимальной полноты и точности, а моя реализация наоборот получила максимальную полноту но меньшую точность."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "mcMUHEhrd-cE"
      },
      "source": [
        "####Дерево решений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrnQs-Oid-cF"
      },
      "source": [
        "\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, data_left=None, data_right=None, gain=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.data_left = data_left\n",
        "        self.data_right = data_right\n",
        "        self.gain = gain\n",
        "        self.value = value\n",
        "\n",
        "class MyDecisionTree:\n",
        "    def __init__(self, min_samples_split=2, max_depth=5):\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.root = None\n",
        "        \n",
        "    @staticmethod\n",
        "    def _entropy(s):\n",
        "        counts = np.bincount(np.array(s, dtype=np.int64))\n",
        "        percentages = counts / len(s)\n",
        "        entropy = 0\n",
        "        for pct in percentages:\n",
        "            if pct > 0:\n",
        "                entropy += pct * np.log2(pct)\n",
        "        return -entropy\n",
        "    \n",
        "    def _information_gain(self, parent, left_child, right_child):\n",
        "        num_left = len(left_child) / len(parent)\n",
        "        num_right = len(right_child) / len(parent)\n",
        "        return self._entropy(parent) - (num_left * self._entropy(left_child) + num_right * self._entropy(right_child))\n",
        "  \n",
        "    def _best_split(self, X, y):\n",
        "        best_split = {}\n",
        "        best_info_gain = -1\n",
        "        n_rows, n_cols = X.shape\n",
        " \n",
        "        for f_idx in range(n_cols):\n",
        "            X_curr = X[:, f_idx]\n",
        "\n",
        "            for threshold in np.unique(X_curr):\n",
        "\n",
        "                df = np.concatenate((X, y.reshape(1, -1).T), axis=1)\n",
        "                df_left = np.array([row for row in df if row[f_idx] <= threshold])\n",
        "                df_right = np.array([row for row in df if row[f_idx] > threshold])\n",
        "\n",
        "                if len(df_left) > 0 and len(df_right) > 0:\n",
        "                    y = df[:, -1]\n",
        "                    y_left = df_left[:, -1]\n",
        "                    y_right = df_right[:, -1]\n",
        "                    gain = self._information_gain(y, y_left, y_right)\n",
        "                    if gain > best_info_gain:\n",
        "                        best_split = {\n",
        "                            'feature_index': f_idx,\n",
        "                            'threshold': threshold,\n",
        "                            'df_left': df_left,\n",
        "                            'df_right': df_right,\n",
        "                            'gain': gain\n",
        "                        }\n",
        "                        best_info_gain = gain\n",
        "        return best_split\n",
        "    \n",
        "    def _build(self, X, y, depth=0):\n",
        "        n_rows, n_cols = X.shape\n",
        "        \n",
        "        if n_rows >= self.min_samples_split and depth <= self.max_depth:\n",
        "            best = self._best_split(X, y)\n",
        "            if best['gain'] > 0:\n",
        "                left = self._build(\n",
        "                    X=best['df_left'][:, :-1], \n",
        "                    y=best['df_left'][:, -1], \n",
        "                    depth=depth + 1\n",
        "                )\n",
        "                right = self._build(\n",
        "                    X=best['df_right'][:, :-1], \n",
        "                    y=best['df_right'][:, -1], \n",
        "                    depth=depth + 1\n",
        "                )\n",
        "                return Node(\n",
        "                    feature=best['feature_index'], \n",
        "                    threshold=best['threshold'], \n",
        "                    data_left=left, \n",
        "                    data_right=right, \n",
        "                    gain=best['gain']\n",
        "                )\n",
        "        return Node(\n",
        "            value=Counter(y).most_common(1)[0][0]\n",
        "        )\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.root = self._build(X, y)\n",
        "        \n",
        "    def _predict(self, x, tree):\n",
        "        if tree.value != None:\n",
        "            return tree.value\n",
        "        feature_value = x[tree.feature]\n",
        "\n",
        "        if feature_value <= tree.threshold:\n",
        "            return self._predict(x=x, tree=tree.data_left)\n",
        "        \n",
        "        if feature_value > tree.threshold:\n",
        "            return self._predict(x=x, tree=tree.data_right)\n",
        "        \n",
        "    def predict(self, X):\n",
        "        return [self._predict(x, self.root) for x in X]"
      ],
      "execution_count": 781,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "BQ-LGt5pd-cH"
      },
      "source": [
        "Моя реализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdQOfOohexK_",
        "outputId": "a579c7cb-0402-448e-92cf-13de7b37a46a"
      },
      "source": [
        "parameters = [(2, 1), (2, 2), (2, 3), (2, 10), (3, 15), \n",
        "              (3, 1), (3, 2), (3, 3), (3, 10), (3, 15), \n",
        "              (4, 1), (4, 2), (4, 3), (4, 10), (4, 15),\n",
        "              (5, 1), (5, 2), (5, 3), (5, 10), (5, 15),\n",
        "              (10, 1), (10, 2), (10, 3), (10, 10), (10, 15)\n",
        "              ]\n",
        "train_max = -1\n",
        "test_max = -1\n",
        "sample_split_max = 0\n",
        "depth_max = 0\n",
        "for i in parameters:\n",
        "    sample_split, depth = i\n",
        "    my_tree = MyDecisionTree(min_samples_split = sample_split, max_depth = depth)\n",
        "    my_tree.fit(X_train, Y_train)\n",
        "    Y_pred_test = my_tree.predict(X_test)\n",
        "    Y_pred_train = my_tree.predict(X_train)\n",
        "    accuracy_train = accuracy_score(Y_train, Y_pred_train)\n",
        "    accuracy_test = accuracy_score(Y_test, Y_pred_test)\n",
        "    if (train_max < accuracy_train and test_max < accuracy_test):\n",
        "      train_max = accuracy_train\n",
        "      test_max = accuracy_test\n",
        "      sample_split_max = sample_split\n",
        "      depth_max = depth \n",
        "print(\"Minimum sample splits:\", sample_split_max, \"Max depth:\", depth_max, \"\\n\", \"Max train accuracy:\", train_max, \"Max test accuracy:\", test_max)"
      ],
      "execution_count": 782,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum sample splits: 2 Max depth: 1 \n",
            " Max train accuracy: 0.7638436482084691 Max test accuracy: 0.7597402597402597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7lKTfWQ93Hk"
      },
      "source": [
        "Лучше всего себя показала модель с количеством образцов равным двум и максимальной глубиной равной 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4t0b7NOar1-"
      },
      "source": [
        "my_tree = MyDecisionTree(2, 1)\n",
        "my_tree.fit(X_train, Y_train)\n",
        "Y_pred = my_tree.predict(X_test)"
      ],
      "execution_count": 783,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiL2YmXqadff"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUkHxeGfd-cI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ddd64d-b293-4a43-8f19-29f725522d8e"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": 784,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[92 15]\n",
            " [22 25]]\n",
            "accuracy: 0.7597402597402597\n",
            "precision: 0.625\n",
            "recall: 0.5319148936170213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "51nlLkFMd-cI"
      },
      "source": [
        "Реализация sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65EmQmGjd-cJ"
      },
      "source": [
        "sk_tree = DecisionTree()\n",
        "sk_tree.fit(X_train, Y_train)\n",
        "Y_pred = sk_tree.predict(X_test)\n"
      ],
      "execution_count": 785,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQEX-6J63H3n"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iDMHfpz3Q9v",
        "outputId": "3fbd223c-e23d-43f3-e35d-008edda290fa"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": 786,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[94 13]\n",
            " [24 23]]\n",
            "accuracy: 0.7597402597402597\n",
            "precision: 0.6388888888888888\n",
            "recall: 0.48936170212765956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94gaAue7-EHU"
      },
      "source": [
        "Можно заметить что реализация sklearn по всем метрикам превзошла мою реализацию кроме recall и кроме того сам recall у двух реализаций довольно низок, поэтому дополнительно рассмотрим F-меру"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BYMa4tnd-cJ"
      },
      "source": [
        "####Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgHtKAeKd-cK"
      },
      "source": [
        "class MyRandomForest:\n",
        "    def __init__(self, num_trees=25, min_samples_split=2, max_depth=5):\n",
        "        self.num_trees = num_trees\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.decision_trees = []\n",
        "        \n",
        "    @staticmethod\n",
        "    def _sample(X, y):\n",
        "        n_rows, n_cols = X.shape\n",
        "        samples = np.random.choice(a=n_rows, size=n_rows, replace=True)\n",
        "        return X[samples], y[samples]\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        if len(self.decision_trees) > 0:\n",
        "            self.decision_trees = []\n",
        "        num_built = 0\n",
        "        while num_built < self.num_trees:\n",
        "            try:\n",
        "                clf = MyDecisionTree(\n",
        "                    min_samples_split=self.min_samples_split,\n",
        "                    max_depth=self.max_depth\n",
        "                )\n",
        "                _X, _y = self._sample(X, y)\n",
        "                clf.fit(_X, _y)\n",
        "                self.decision_trees.append(clf)\n",
        "                num_built += 1\n",
        "            except Exception as e:\n",
        "                continue\n",
        "    \n",
        "    def predict(self, X):\n",
        "        y = []\n",
        "        for tree in self.decision_trees:\n",
        "            y.append(tree.predict(X))\n",
        "        y = np.swapaxes(a=y, axis1=0, axis2=1)\n",
        "        predictions = []\n",
        "        for preds in y:\n",
        "            counter = Counter(preds)\n",
        "            predictions.append(counter.most_common(1)[0][0])\n",
        "        return predictions"
      ],
      "execution_count": 788,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "2H47Y3-mCbQy"
      },
      "source": [
        "Моя реализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "QxYl393ffAGv",
        "outputId": "77bc31c2-b27c-4fd6-b80b-6601eabf73d2"
      },
      "source": [
        "parameters = [(2, 2, 1), (5, 2, 1), (10, 2, 1), (20, 2, 1), (50, 2, 1)]\n",
        "train_max = -1\n",
        "test_max = -1\n",
        "sample_split_max = 0\n",
        "depth_max = 0\n",
        "tree_count_max = 0\n",
        "for i in parameters:\n",
        "    tree_count, sample_split, depth = i\n",
        "    my_forest = MyRandomForest(num_trees = tree_count, min_samples_split = sample_split, max_depth = depth)\n",
        "    my_forest.fit(X_train, Y_train)\n",
        "    Y_pred_test = my_forest.predict(X_test)\n",
        "    Y_pred_train = my_forest.predict(X_train)\n",
        "    accuracy_train = accuracy_score(Y_train, Y_pred_train)\n",
        "    accuracy_test = accuracy_score(Y_test, Y_pred_test)\n",
        "    if (train_max < accuracy_train and test_max < accuracy_test):\n",
        "      train_max = accuracy_train\n",
        "      test_max = accuracy_test\n",
        "      sample_split_max = sample_split\n",
        "      depth_max = depth\n",
        "      tree_count_max = tree_count\n",
        "print(\"Tree count:\", tree_count_max, \"Minimum sample splits:\", sample_split_max, \"Max depth:\", depth_max, \"\\n\", \"Max train accuracy:\", train_max, \"Max test accuracy:\", test_max)"
      ],
      "execution_count": 789,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-789-264f4d47230e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtree_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmy_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmy_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mY_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mY_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-788-ab4d634a0c77>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 )\n\u001b[1;32m     24\u001b[0m                 \u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_trees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mnum_built\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-781-a1f637e47487>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-781-a1f637e47487>\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_best_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gain'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 left = self._build(\n",
            "\u001b[0;32m<ipython-input-781-a1f637e47487>\u001b[0m in \u001b[0;36m_best_split\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mdf_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mdf_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_left\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_right\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArQjJ_GmBtGd"
      },
      "source": [
        "Лучше всего себя показала модель с количеством деревьев равным 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_otYQcNJC917"
      },
      "source": [
        "my_forest = MyRandomForest(5, 2, 1)\n",
        "my_forest.fit(X_train, Y_train)\n",
        "Y_pred = my_tree.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQdyW2LkCenG"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kAXx0gNC-V3"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "NCOW1slvC6pu"
      },
      "source": [
        "Реализация sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzcr-TGmC-xL"
      },
      "source": [
        "sk_forest = RandomForestClassifier()\n",
        "sk_forest.fit(X_train, Y_train)\n",
        "Y_pred = sk_forest.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRNKh7gmC7z2"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWgn_oGpC_Ul"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))\n",
        "print(\"f1_score\", f1_score(Y_test, Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}