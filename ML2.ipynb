{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq0wc3K0kBqA"
      },
      "source": [
        "# Лабораторная работа 2 по МО"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s8Spsp5d-b-"
      },
      "source": [
        "Выбранный набор данных позволяет нам предсказать вероятность появления диабета у инидийских пим в течение 5 лет, исходя из различных медицинских параметров."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMnfK4-xd-b_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics  \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "dataframe = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv', header=None)\n",
        "dataframe.columns = ['Times pregnant', 'Glucose concentration', 'Blood pressure', 'Skinfold thickness', 'Serum insulin',\n",
        "                     'BMI', 'Pedigree', 'Age', 'Class']\n",
        "del dataframe['Skinfold thickness']\n",
        "del dataframe['Serum insulin']\n",
        "dataframe['Glucose concentration'] = dataframe['Glucose concentration'].replace(0, dataframe['Glucose concentration'].std())\n",
        "dataframe['Blood pressure'] = dataframe['Blood pressure'].replace(0, dataframe['Blood pressure'].std())\n",
        "dataframe['BMI'] = dataframe['BMI'].replace(0, dataframe['BMI'].std())\n",
        "\n"
      ],
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy_2cdtpd-cA"
      },
      "source": [
        "Вывод статистических данных для атрибутов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIZ7AToOd-cA",
        "outputId": "b9862515-19ee-4adb-8c84-ab44ddf253f8"
      },
      "source": [
        "print(dataframe.head())\n",
        "print(\"Размеры:\",dataframe.shape)\n",
        "print(\"Устройство:\\n\",dataframe.dtypes)"
      ],
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Times pregnant  Glucose concentration  Blood pressure  ...  Pedigree  Age  Class\n",
            "0               6                  148.0            72.0  ...     0.627   50      1\n",
            "1               1                   85.0            66.0  ...     0.351   31      0\n",
            "2               8                  183.0            64.0  ...     0.672   32      1\n",
            "3               1                   89.0            66.0  ...     0.167   21      0\n",
            "4               0                  137.0            40.0  ...     2.288   33      1\n",
            "\n",
            "[5 rows x 7 columns]\n",
            "Размеры: (768, 7)\n",
            "Устройство:\n",
            " Times pregnant             int64\n",
            "Glucose concentration    float64\n",
            "Blood pressure           float64\n",
            "BMI                      float64\n",
            "Pedigree                 float64\n",
            "Age                        int64\n",
            "Class                      int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_AYsxBNd-cC"
      },
      "source": [
        "Подгружаем данные и переводим их в удобный формат:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V-8EUm6aGzf"
      },
      "source": [
        "\n",
        "X = dataframe.iloc[:, :-1].values\n",
        "Y = dataframe.iloc[:, 6].values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,  random_state=0)\n",
        "trans = StandardScaler()\n",
        "X_train = trans.fit_transform(X_train)\n",
        "X_test = trans.fit_transform(X_test)"
      ],
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U7R5bUXuvqh",
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5"
      },
      "source": [
        "Требуемые библиотеки для моей и стандартной реализации:\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPBE_0aYd-cC"
      },
      "source": [
        "from numpy import log, dot, e\n",
        "from numpy.random import rand"
      ],
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "a1kb_nnkd-cD"
      },
      "source": [
        "    ####Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxMBxq3Bd-cD"
      },
      "source": [
        "class MyLogisticRegression:\n",
        "    def sigmoid(self, z): return 1 / (1 + e**(-z))\n",
        "    \n",
        "    def cost_function(self, X, y, weights):                 \n",
        "        z = dot(X, weights)\n",
        "        predict_1 = y * log(self.sigmoid(z))\n",
        "        predict_0 = (1 - y) * log(1 - self.sigmoid(z))\n",
        "        return -sum(predict_1 + predict_0) / len(X)\n",
        "    \n",
        "    def fit(self, X, y, epochs=25, lr=0.05):        \n",
        "        loss = []\n",
        "        weights = rand(X.shape[1])\n",
        "        N = len(X)\n",
        "                 \n",
        "        for _ in range(epochs):        \n",
        "            # Gradient Descent\n",
        "            y_hat = self.sigmoid(dot(X, weights))\n",
        "            weights -= lr * dot(X.T,  y_hat - y) / N            \n",
        "            # Saving Progress\n",
        "            loss.append(self.cost_function(X, y, weights)) \n",
        "            \n",
        "        self.weights = weights\n",
        "        self.loss = loss\n",
        "    \n",
        "    def predict(self, X):        \n",
        "        # Predicting with sigmoid function\n",
        "        z = dot(X, self.weights)\n",
        "        # Returning binary result\n",
        "        return [1 if i > 0.5 else 0 for i in self.sigmoid(z)]"
      ],
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCqg-UkXosq5"
      },
      "source": [
        "Моя реализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3UGxlOhoy6L",
        "outputId": "9eb78441-f09f-4670-d66d-ff3f36643327"
      },
      "source": [
        "parameters = [(0.1, 50), (0.01, 500), (0.001, 5000), (0.0001, 50000), (0.00001, 100000)]\n",
        "for i in parameters:\n",
        "    learning_rate, epochs = i\n",
        "    my_regr = MyLogisticRegression()\n",
        "    my_regr.fit(X_train, Y_train, epochs, learning_rate)\n",
        "    Y_pred_test = my_regr.predict(X_test)\n",
        "    Y_pred_train = my_regr.predict(X_train)\n",
        "    print(\"Learning rate\", learning_rate, \"epochs\", epochs, \"accuracy_test\", np.mean(Y_train == Y_pred_train), \"accuracy_train\", np.mean(Y_test == Y_pred_test))\n",
        "\n",
        "    "
      ],
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate 0.1 epochs 50 accuracy_test 0.7052117263843648 accuracy_train 0.7402597402597403\n",
            "Learning rate 0.01 epochs 500 accuracy_test 0.7052117263843648 accuracy_train 0.7532467532467533\n",
            "Learning rate 0.001 epochs 5000 accuracy_test 0.7263843648208469 accuracy_train 0.7467532467532467\n",
            "Learning rate 0.0001 epochs 50000 accuracy_test 0.7149837133550488 accuracy_train 0.7532467532467533\n",
            "Learning rate 1e-05 epochs 100000 accuracy_test 0.6970684039087948 accuracy_train 0.7597402597402597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7lCggrTpYwz"
      },
      "source": [
        "Лучше всего себя показала модель с learning_rate равным 0.0001 и количеством эпох равным 10000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqx2kIKGfc62"
      },
      "source": [
        "my_regr = MyLogisticRegression()\n",
        "my_regr.fit(X_train, Y_train, 10000, 0.0001)\n",
        "Y_pred = my_regr.predict(X_test)"
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O70LsbfRe71D"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WLHjtB-fAB8",
        "outputId": "3c92f64a-1013-46ea-a6ae-bae1b911e3b0"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[78 29]\n",
            " [ 6 41]]\n",
            "accuracy: 0.7727272727272727\n",
            "precision: 0.5857142857142857\n",
            "recall: 0.8723404255319149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eAb7NjKov0s"
      },
      "source": [
        "Реализация sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceHthIFqpuSO"
      },
      "source": [
        "sk_regr = LogisticRegression().fit(X_train, Y_train)\n",
        "Y_pred = sk_regr.predict(X_test)"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x9DOR7QfD5G"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPOb5nAdfGRn",
        "outputId": "fd5bd3f2-f7da-4662-b96c-df1caa2af0e1"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))"
      ],
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[94 13]\n",
            " [18 29]]\n",
            "accuracy: 0.7987012987012987\n",
            "precision: 0.6904761904761905\n",
            "recall: 0.6170212765957447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "mcMUHEhrd-cE"
      },
      "source": [
        "####Дерево решений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrnQs-Oid-cF"
      },
      "source": [
        "\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, data_left=None, data_right=None, gain=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.data_left = data_left\n",
        "        self.data_right = data_right\n",
        "        self.gain = gain\n",
        "        self.value = value\n",
        "\n",
        "class MyDecisionTree:\n",
        "    def __init__(self, min_samples_split=2, max_depth=5):\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.root = None\n",
        "        \n",
        "    @staticmethod\n",
        "    def _entropy(s):\n",
        "        counts = np.bincount(np.array(s, dtype=np.int64))\n",
        "        percentages = counts / len(s)\n",
        "        entropy = 0\n",
        "        for pct in percentages:\n",
        "            if pct > 0:\n",
        "                entropy += pct * np.log2(pct)\n",
        "        return -entropy\n",
        "    \n",
        "    def _information_gain(self, parent, left_child, right_child):\n",
        "        num_left = len(left_child) / len(parent)\n",
        "        num_right = len(right_child) / len(parent)\n",
        "        return self._entropy(parent) - (num_left * self._entropy(left_child) + num_right * self._entropy(right_child))\n",
        "  \n",
        "    def _best_split(self, X, y):\n",
        "        best_split = {}\n",
        "        best_info_gain = -1\n",
        "        n_rows, n_cols = X.shape\n",
        " \n",
        "        for f_idx in range(n_cols):\n",
        "            X_curr = X[:, f_idx]\n",
        "\n",
        "            for threshold in np.unique(X_curr):\n",
        "\n",
        "                df = np.concatenate((X, y.reshape(1, -1).T), axis=1)\n",
        "                df_left = np.array([row for row in df if row[f_idx] <= threshold])\n",
        "                df_right = np.array([row for row in df if row[f_idx] > threshold])\n",
        "\n",
        "                if len(df_left) > 0 and len(df_right) > 0:\n",
        "                    y = df[:, -1]\n",
        "                    y_left = df_left[:, -1]\n",
        "                    y_right = df_right[:, -1]\n",
        "                    gain = self._information_gain(y, y_left, y_right)\n",
        "                    if gain > best_info_gain:\n",
        "                        best_split = {\n",
        "                            'feature_index': f_idx,\n",
        "                            'threshold': threshold,\n",
        "                            'df_left': df_left,\n",
        "                            'df_right': df_right,\n",
        "                            'gain': gain\n",
        "                        }\n",
        "                        best_info_gain = gain\n",
        "        return best_split\n",
        "    \n",
        "    def _build(self, X, y, depth=0):\n",
        "        n_rows, n_cols = X.shape\n",
        "        \n",
        "        if n_rows >= self.min_samples_split and depth <= self.max_depth:\n",
        "            best = self._best_split(X, y)\n",
        "            if best['gain'] > 0:\n",
        "                left = self._build(\n",
        "                    X=best['df_left'][:, :-1], \n",
        "                    y=best['df_left'][:, -1], \n",
        "                    depth=depth + 1\n",
        "                )\n",
        "                right = self._build(\n",
        "                    X=best['df_right'][:, :-1], \n",
        "                    y=best['df_right'][:, -1], \n",
        "                    depth=depth + 1\n",
        "                )\n",
        "                return Node(\n",
        "                    feature=best['feature_index'], \n",
        "                    threshold=best['threshold'], \n",
        "                    data_left=left, \n",
        "                    data_right=right, \n",
        "                    gain=best['gain']\n",
        "                )\n",
        "        return Node(\n",
        "            value=Counter(y).most_common(1)[0][0]\n",
        "        )\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.root = self._build(X, y)\n",
        "        \n",
        "    def _predict(self, x, tree):\n",
        "        if tree.value != None:\n",
        "            return tree.value\n",
        "        feature_value = x[tree.feature]\n",
        "\n",
        "        if feature_value <= tree.threshold:\n",
        "            return self._predict(x=x, tree=tree.data_left)\n",
        "        \n",
        "        if feature_value > tree.threshold:\n",
        "            return self._predict(x=x, tree=tree.data_right)\n",
        "        \n",
        "    def predict(self, X):\n",
        "        return [self._predict(x, self.root) for x in X]"
      ],
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "BQ-LGt5pd-cH"
      },
      "source": [
        "Моя реализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdQOfOohexK_",
        "outputId": "22497f2b-28b8-4cca-ac7e-a554167e2cf5"
      },
      "source": [
        "parameters = [(2, 5), (3, 6), (4, 7), (5, 8), (6, 9)]\n",
        "for i in parameters:\n",
        "    sample_split, depth = i\n",
        "    my_tree = MyDecisionTree(sample_split, depth)\n",
        "    my_tree.fit(X_train, Y_train)\n",
        "    Y_pred_test = my_tree.predict(X_test)\n",
        "    Y_pred_train = my_tree.predict(X_train)\n",
        "    print(\"Minimum sample splits\", sample_split, \"Max depth\", depth, \"accuracy_test\", np.mean(Y_train == Y_pred_train), \"accuracy_train\", np.mean(Y_test == Y_pred_test))"
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum sample splits 2 Max depth 5 accuracy_test 0.8192182410423453 accuracy_train 0.7597402597402597\n",
            "Minimum sample splits 3 Max depth 6 accuracy_test 0.8697068403908795 accuracy_train 0.6883116883116883\n",
            "Minimum sample splits 4 Max depth 7 accuracy_test 0.8859934853420195 accuracy_train 0.7142857142857143\n",
            "Minimum sample splits 5 Max depth 8 accuracy_test 0.9218241042345277 accuracy_train 0.7077922077922078\n",
            "Minimum sample splits 6 Max depth 9 accuracy_test 0.9332247557003257 accuracy_train 0.7077922077922078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4t0b7NOar1-"
      },
      "source": [
        "my_tree = MyDecisionTree(2, 5)\n",
        "my_tree.fit(X_train, Y_train)\n",
        "Y_pred = my_tree.predict(X_test)"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiL2YmXqadff"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUkHxeGfd-cI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd58bbc0-322e-4010-9f6d-01f15a28acc8"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[94 13]\n",
            " [24 23]]\n",
            "accuracy: 0.7597402597402597\n",
            "precision: 0.6388888888888888\n",
            "recall: 0.48936170212765956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "51nlLkFMd-cI"
      },
      "source": [
        "Реализация sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65EmQmGjd-cJ"
      },
      "source": [
        "sk_tree = DecisionTree()\n",
        "sk_tree.fit(X_train, Y_train)\n",
        "Y_pred = sk_tree.predict(X_test)\n"
      ],
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQEX-6J63H3n"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iDMHfpz3Q9v",
        "outputId": "ab05ce0d-a671-4e81-cad2-41ee844af7f7"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))"
      ],
      "execution_count": 392,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[94 13]\n",
            " [24 23]]\n",
            "accuracy: 0.7597402597402597\n",
            "precision: 0.6388888888888888\n",
            "recall: 0.48936170212765956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BYMa4tnd-cJ"
      },
      "source": [
        "####Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgHtKAeKd-cK"
      },
      "source": [
        "class MyRandomForest:\n",
        "    def __init__(self, num_trees=25, min_samples_split=2, max_depth=5):\n",
        "        self.num_trees = num_trees\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.decision_trees = []\n",
        "        \n",
        "    @staticmethod\n",
        "    def _sample(X, y):\n",
        "        n_rows, n_cols = X.shape\n",
        "        samples = np.random.choice(a=n_rows, size=n_rows, replace=True)\n",
        "        return X[samples], y[samples]\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        if len(self.decision_trees) > 0:\n",
        "            self.decision_trees = []\n",
        "        num_built = 0\n",
        "        while num_built < self.num_trees:\n",
        "            try:\n",
        "                clf = MyDecisionTree(\n",
        "                    min_samples_split=self.min_samples_split,\n",
        "                    max_depth=self.max_depth\n",
        "                )\n",
        "                _X, _y = self._sample(X, y)\n",
        "                clf.fit(_X, _y)\n",
        "                self.decision_trees.append(clf)\n",
        "                num_built += 1\n",
        "            except Exception as e:\n",
        "                continue\n",
        "    \n",
        "    def predict(self, X):\n",
        "        y = []\n",
        "        for tree in self.decision_trees:\n",
        "            y.append(tree.predict(X))\n",
        "        y = np.swapaxes(a=y, axis1=0, axis2=1)\n",
        "        predictions = []\n",
        "        for preds in y:\n",
        "            counter = Counter(x)\n",
        "            predictions.append(counter.most_common(1)[0][0])\n",
        "        return predictions"
      ],
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "2H47Y3-mCbQy"
      },
      "source": [
        "Моя реализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxYl393ffAGv"
      },
      "source": [
        "parameters = [(2, 5), (3, 6), (4, 7), (5, 8), (6, 9)]\n",
        "for i in parameters:\n",
        "    sample_split, depth = i\n",
        "    my_tree = MyDecisionTree(sample_split, depth)\n",
        "    my_tree.fit(X_train, Y_train)\n",
        "    Y_pred_test = my_tree.predict(X_test)\n",
        "    Y_pred_train = my_tree.predict(X_train)\n",
        "    print(\"Minimum sample splits\", sample_split, \"Max depth\", depth, \"accuracy_test\", np.mean(Y_train == Y_pred_train), \"accuracy_train\", np.mean(Y_test == Y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_otYQcNJC917"
      },
      "source": [
        "my_forest = MyRandomForest(2, 5)\n",
        "my_forest.fit(X_train, Y_train)\n",
        "Y_pred = my_tree.predict(X_test)\n"
      ],
      "execution_count": 405,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQdyW2LkCenG"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kAXx0gNC-V3",
        "outputId": "115118f6-f6f8-4a56-efdf-d3b1e731eef0"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[75 32]\n",
            " [13 34]]\n",
            "accuracy: 0.7077922077922078\n",
            "precision: 0.5151515151515151\n",
            "recall: 0.723404255319149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "outputId": "6b46cd0b-ae73-48b6-9e97-cda5553c69b5",
        "id": "NCOW1slvC6pu"
      },
      "source": [
        "Реализация sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzcr-TGmC-xL"
      },
      "source": [
        "sk_forest = RandomForestClassifier()\n",
        "sk_forest.fit(X_train, Y_train)\n",
        "Y_pred = sk_forest.predict(X_test)"
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRNKh7gmC7z2"
      },
      "source": [
        "Получим матрицу ошибок и метрики классификатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWgn_oGpC_Ul",
        "outputId": "6b672424-affe-4ab8-9333-4e0f9b1d12f1"
      },
      "source": [
        "print(\"confusion matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
        "print(\"accuracy:\",accuracy_score(Y_test, Y_pred))\n",
        "print(\"precision:\",precision_score(Y_test, Y_pred))\n",
        "print(\"recall:\",recall_score(Y_test, Y_pred))"
      ],
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix:\n",
            " [[95 12]\n",
            " [17 30]]\n",
            "accuracy: 0.8116883116883117\n",
            "precision: 0.7142857142857143\n",
            "recall: 0.6382978723404256\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}